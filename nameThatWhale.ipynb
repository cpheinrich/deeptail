{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from: https://www.kaggle.com/c/whale-categorization-playground\n",
    "\n",
    "I renamed train.csv -> targets.csv and the train directory to kaggle_train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image', 'Id']\n",
      "9850\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "fname = os.path.join(home_dir, 'targets.csv') # targets for both train and validation\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "lines = lines[:-1]\n",
    "\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding the whale ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "whale_ids = [line.split(',')[1] for line in lines]\n",
    "whale_ids = set(whale_ids) # convert to set to remove duplicats\n",
    "whale_ids = list(whale_ids) # convert back to list to make it ordered\n",
    "\n",
    "whale_dict = {}\n",
    "for i, whale in enumerate(whale_ids):\n",
    "    vec = np.zeros(len(whale_ids))\n",
    "    vec[i] = 1\n",
    "    whale_dict[whale] = vec\n",
    "    \n",
    "def whale2vec(whale): # returns a unique one-hot encoded vector given \n",
    "    if whale in whale_dict.keys():\n",
    "        return whale_dict[whale]\n",
    "    else:\n",
    "        print(\"whale not found. Returning new_whale vector\")\n",
    "        return whale_dict['new_whale']\n",
    "               \n",
    "vec = whale2vec(whale_ids[2])\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import errno \n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split the training images into a train and validation set, and then subdivide them into directories for each whale_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "original_dataset_dir = os.path.join(home_dir, 'kaggle_train')\n",
    "\n",
    "train_dir = os.path.join(home_dir, 'train')\n",
    "mkdir_p(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(home_dir, 'validation')\n",
    "mkdir_p(validation_dir)\n",
    "\n",
    "# Let's then create a subdirectory for each whale_id in both the train and validation directories \n",
    "# so we can use the ImageDataGenerator magic function\n",
    "\n",
    "for whale_id in whale_ids:\n",
    "    mkdir_p(os.path.join(train_dir, whale_id))\n",
    "    mkdir_p(os.path.join(validation_dir, whale_id))\n",
    "    \n",
    "# Copy first 7500 files into the appropriate whale directory in train dir    \n",
    "for i in range(7500):\n",
    "    pic = lines[i].split(',')[0]\n",
    "    whale_id = lines[i].split(',')[1]\n",
    "    src = os.path.join(original_dataset_dir, pic)\n",
    "    whale_id_dir = os.path.join(train_dir, whale_id)\n",
    "    dst = os.path.join(whale_id_dir, pic)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# copy the rest into the appropriate whale directory in validation dir    \n",
    "for i in range(7500,len(lines)):\n",
    "    pic = lines[i].split(',')[0]\n",
    "    whale_id = lines[i].split(',')[1]\n",
    "    src = os.path.join(original_dataset_dir, pic)\n",
    "    whale_id_dir = os.path.join(validation_dir, whale_id)\n",
    "    dst = os.path.join(whale_id_dir, pic)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 4251 classes.\n",
      "Found 2350 images belonging to 4251 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "image_size = (100,100)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to image_size - define above\n",
    "        target_size=image_size,\n",
    "        color_mode='grayscale',\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        validation_dir,\n",
    "        # All images will be resized to image_size - define above\n",
    "        target_size=image_size,\n",
    "        color_mode='grayscale',\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(image_size[0],image_size[1],1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(len(whale_ids), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 98, 98, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 49, 49, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 23, 23, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 21, 21, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 10, 10, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4251)              2180763   \n",
      "=================================================================\n",
      "Total params: 3,470,107\n",
      "Trainable params: 3,470,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 182s 487ms/step - loss: 8.0342 - acc: 0.0853 - val_loss: 8.0459 - val_acc: 0.0710\n",
      "Epoch 2/20\n",
      "286/375 [=====================>........] - ETA: 37s - loss: 7.7743 - acc: 0.0851"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=375, # with a batch size of 20, 375 steps will get us through the 7500 images\n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
