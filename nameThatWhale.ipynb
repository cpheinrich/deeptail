{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data downloaded from: https://www.kaggle.com/c/whale-categorization-playground\n",
    "\n",
    "I renamed train.csv -> targets.csv and the train directory to kaggle_train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image', 'Id']\n",
      "9850\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "fname = os.path.join(home_dir, 'targets.csv') # targets for both train and validation\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "lines = lines[:-1]\n",
    "\n",
    "print(header)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding the whale ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4251\n",
      "[ 0.  0.  1. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "whale_ids = [line.split(',')[1] for line in lines]\n",
    "whale_ids = set(whale_ids) # convert to set to remove duplicats\n",
    "whale_ids = list(whale_ids) # convert back to list to make it ordered\n",
    "\n",
    "\n",
    "# Am no longer using the whale2vec function, sinc the ImageDataGenerator automatically one-hot-encodes the \n",
    "# targets\n",
    "whale_dict = {}\n",
    "for i, whale in enumerate(whale_ids):\n",
    "    vec = np.zeros(len(whale_ids))\n",
    "    vec[i] = 1\n",
    "    whale_dict[whale] = vec\n",
    "    \n",
    "def whale2vec(whale): # returns a unique one-hot encoded vector given \n",
    "    if whale in whale_dict.keys():\n",
    "        return whale_dict[whale]\n",
    "    else:\n",
    "        print(\"whale not found. Returning new_whale vector\")\n",
    "        return whale_dict['new_whale']\n",
    "               \n",
    "vec = whale2vec(whale_ids[2])\n",
    "print(len(whale_ids))\n",
    "print(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import errno \n",
    "\n",
    "def mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc:  # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we split the training images into a train and validation set, and then subdivide them into directories for each whale_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "original_dataset_dir = os.path.join(home_dir, 'kaggle_train')\n",
    "\n",
    "train_dir = os.path.join(home_dir, 'train')\n",
    "mkdir_p(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(home_dir, 'validation')\n",
    "mkdir_p(validation_dir)\n",
    "\n",
    "# Let's then create a subdirectory for each whale_id in both the train and validation directories \n",
    "# so we can use the ImageDataGenerator magic function\n",
    "\n",
    "for whale_id in whale_ids:\n",
    "    mkdir_p(os.path.join(train_dir, whale_id))\n",
    "    mkdir_p(os.path.join(validation_dir, whale_id))\n",
    "    \n",
    "# Copy first 7500 files into the appropriate whale directory in train dir    \n",
    "for i in range(7500):\n",
    "    pic = lines[i].split(',')[0]\n",
    "    whale_id = lines[i].split(',')[1]\n",
    "    src = os.path.join(original_dataset_dir, pic)\n",
    "    whale_id_dir = os.path.join(train_dir, whale_id)\n",
    "    dst = os.path.join(whale_id_dir, pic)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "# copy the rest into the appropriate whale directory in validation dir    \n",
    "for i in range(7500,len(lines)):\n",
    "    pic = lines[i].split(',')[0]\n",
    "    whale_id = lines[i].split(',')[1]\n",
    "    src = os.path.join(original_dataset_dir, pic)\n",
    "    whale_id_dir = os.path.join(validation_dir, whale_id)\n",
    "    dst = os.path.join(whale_id_dir, pic)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 4251 classes.\n",
      "Found 2350 images belonging to 4251 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_size = (180,180) #adjustable parameter for processed image_size. Run time should \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to image_size - define above\n",
    "        target_size=image_size,\n",
    "        color_mode='rgb', # input images are RGB and grayscale, but we map them all onto \n",
    "                                # which should be suitable for whale tails anyway\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        validation_dir,\n",
    "        # All images will be resized to image_size - define above\n",
    "        target_size=image_size,\n",
    "        color_mode='rgb',\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3),activation='relu',input_shape=(image_size[0],image_size[1],3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(8192, activation='relu'))\n",
    "model.add(layers.Dense(len(whale_ids), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 178, 178, 32)      320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 89, 89, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 87, 87, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 43, 43, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 41, 41, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10368)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8192)              84942848  \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4251)              34828443  \n",
      "=================================================================\n",
      "Total params: 120,011,547\n",
      "Trainable params: 120,011,547\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "375/375 [==============================] - 787s 2s/step - loss: 8.0286 - acc: 0.0857 - val_loss: 8.1145 - val_acc: 0.0760\n",
      "Epoch 2/20\n",
      "375/375 [==============================] - 763s 2s/step - loss: 7.7825 - acc: 0.0860 - val_loss: 8.0932 - val_acc: 0.0760\n",
      "Epoch 3/20\n",
      "375/375 [==============================] - 771s 2s/step - loss: 7.6613 - acc: 0.0860 - val_loss: 8.5058 - val_acc: 0.0760\n",
      "Epoch 4/20\n",
      "262/375 [===================>..........] - ETA: 3:43 - loss: 7.4480 - acc: 0.0876"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-258f754dc61c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       validation_steps=50)\n\u001b[0m",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m                                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2145\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2146\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2147\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=375, # batch size is 20, 375 steps will get us through\n",
    "    7500 images\n",
    "      epochs=20,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using a pre-trained convolutional base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.4/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import Xception\n",
    "\n",
    "conv_base = Xception(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(image_size[0], image_size[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 180, 180, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 89, 89, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 89, 89, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 89, 89, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 87, 87, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 87, 87, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 87, 87, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 87, 87, 128)  8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 87, 87, 128)  512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 87, 87, 128)  0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 87, 87, 128)  17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 87, 87, 128)  512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 44, 44, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 44, 44, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 44, 44, 128)  512         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 44, 44, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 44, 44, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 44, 44, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 44, 44, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 44, 44, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 44, 44, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 44, 44, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 22, 22, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 22, 22, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 22, 22, 256)  1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 22, 22, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 22, 22, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 22, 22, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 22, 22, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 22, 22, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 22, 22, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 22, 22, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 11, 11, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 11, 11, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 11, 11, 728)  2912        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 11, 11, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 11, 11, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 11, 11, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 11, 11, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 11, 11, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 11, 11, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 11, 11, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 11, 11, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 11, 11, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 11, 11, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 11, 11, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 11, 11, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 11, 11, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 11, 11, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 11, 11, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 11, 11, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 11, 11, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 11, 11, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 11, 11, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 11, 11, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 11, 11, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 11, 11, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 11, 11, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 11, 11, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 11, 11, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 11, 11, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 11, 11, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 11, 11, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 11, 11, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 11, 11, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 11, 11, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 11, 11, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 11, 11, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 11, 11, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 11, 11, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 11, 11, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 11, 11, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 11, 11, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 11, 11, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 11, 11, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 11, 11, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 11, 11, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 11, 11, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 11, 11, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 11, 11, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 11, 11, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 11, 11, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 11, 11, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 11, 11, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 11, 11, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 11, 11, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 11, 11, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 11, 11, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 11, 11, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 11, 11, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 11, 11, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 11, 11, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 11, 11, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 11, 11, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 11, 11, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 11, 11, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 11, 11, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 11, 11, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 11, 11, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 11, 11, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 11, 11, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 11, 11, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 11, 11, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 11, 11, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 11, 11, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 11, 11, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 11, 11, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 11, 11, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 11, 11, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 11, 11, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 11, 11, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 11, 11, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 11, 11, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 11, 11, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 11, 11, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 11, 11, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 11, 11, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 11, 11, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 11, 11, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 11, 11, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 11, 11, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 11, 11, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 6, 6, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 6, 6, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 6, 6, 1024)   4096        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 6, 6, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 6, 6, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 6, 6, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 6, 6, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 6, 6, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 6, 6, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 6, 6, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final feature map has shape `(6, 6, 2048)`. That's the feature on top of which we will stick a densely-connected classifier.\n",
    "\n",
    "At this point, there are two ways we could proceed: \n",
    "\n",
    "* Running the convolutional base over our dataset, recording its output to a Numpy array on disk, then using this data as input to a \n",
    "standalone densely-connected classifier similar to those you have seen in the first chapters of this book. This solution is very fast and \n",
    "cheap to run, because it only requires running the convolutional base once for every input image, and the convolutional base is by far the \n",
    "most expensive part of the pipeline. However, for the exact same reason, this technique would not allow us to leverage data augmentation at \n",
    "all.\n",
    "* Extending the model we have (`conv_base`) by adding `Dense` layers on top, and running the whole thing end-to-end on the input data. This \n",
    "allows us to use data augmentation, because every input image is going through the convolutional base every time it is seen by the model. \n",
    "However, for this same reason, this technique is far more expensive than the first one.\n",
    "\n",
    "We will cover both techniques. Let's walk through the code required to set-up the first one: recording the output of `conv_base` on our \n",
    "data and using these outputs as inputs to a new model.\n",
    "\n",
    "We will start by simply running instances of the previously-introduced `ImageDataGenerator` to extract images as Numpy arrays as well as \n",
    "their labels. We will extract features from these images simply by calling the `predict` method of the `conv_base` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7500 images belonging to 4251 classes.\n",
      "Found 2350 images belonging to 4251 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "train_dir = os.path.join(home_dir, 'train')\n",
    "validation_dir = os.path.join(home_dir, 'validation')\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 20\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 6, 6, 2048))\n",
    "    classes_count = len(whale_ids)\n",
    "    labels = np.zeros(shape=(sample_count, len(whale_ids)))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=image_size,\n",
    "        color_mode='rgb',\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical')\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Note that since generators yield data indefinitely in a loop,\n",
    "            # we must `break` after every image has been seen once.\n",
    "            break\n",
    "    return features, labels\n",
    "\n",
    "train_features, train_labels = extract_features(train_dir, 7500)\n",
    "validation_features, validation_labels = extract_features(validation_dir, len(lines) - 7500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features,(7500, 6*6*2048))\n",
    "validation_features = np.reshape(validation_features, (len(lines)-7500, 6*6*2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 512)               37749248  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4251)              2180763   \n",
      "=================================================================\n",
      "Total params: 39,930,011\n",
      "Trainable params: 39,930,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_dim=6*6*2048)) # we can play around with \n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(len(whale_ids), activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7500 samples, validate on 2350 samples\n",
      "Epoch 1/50\n",
      "7500/7500 [==============================] - 185s 25ms/step - loss: 8.1076 - acc: 0.0840 - val_loss: 8.0316 - val_acc: 0.0702\n",
      "Epoch 2/50\n",
      "7500/7500 [==============================] - 182s 24ms/step - loss: 7.7747 - acc: 0.0860 - val_loss: 7.9341 - val_acc: 0.0702\n",
      "Epoch 3/50\n",
      "7500/7500 [==============================] - 183s 24ms/step - loss: 7.4756 - acc: 0.0869 - val_loss: 7.8723 - val_acc: 0.0711\n",
      "Epoch 4/50\n",
      "7500/7500 [==============================] - 188s 25ms/step - loss: 7.2171 - acc: 0.0877 - val_loss: 7.8199 - val_acc: 0.0711\n",
      "Epoch 5/50\n",
      "7500/7500 [==============================] - 183s 24ms/step - loss: 6.9607 - acc: 0.0913 - val_loss: 7.8075 - val_acc: 0.0732\n",
      "Epoch 6/50\n",
      "7500/7500 [==============================] - 187s 25ms/step - loss: 6.7357 - acc: 0.0965 - val_loss: 7.8119 - val_acc: 0.0740\n",
      "Epoch 7/50\n",
      "7500/7500 [==============================] - 182s 24ms/step - loss: 6.5123 - acc: 0.0996 - val_loss: 7.7928 - val_acc: 0.0766\n",
      "Epoch 8/50\n",
      "7500/7500 [==============================] - 184s 24ms/step - loss: 6.3253 - acc: 0.1048 - val_loss: 7.8140 - val_acc: 0.0753\n",
      "Epoch 9/50\n",
      "7500/7500 [==============================] - 182s 24ms/step - loss: 6.1471 - acc: 0.1103 - val_loss: 7.8357 - val_acc: 0.0736\n",
      "Epoch 10/50\n",
      "7500/7500 [==============================] - 181s 24ms/step - loss: 5.9693 - acc: 0.1169 - val_loss: 7.7887 - val_acc: 0.0774\n",
      "Epoch 11/50\n",
      "7500/7500 [==============================] - 180s 24ms/step - loss: 5.8204 - acc: 0.1229 - val_loss: 7.8631 - val_acc: 0.0732\n",
      "Epoch 12/50\n",
      "7500/7500 [==============================] - 180s 24ms/step - loss: 5.6561 - acc: 0.1284 - val_loss: 7.8798 - val_acc: 0.0791\n",
      "Epoch 13/50\n",
      "7500/7500 [==============================] - 283s 38ms/step - loss: 5.5202 - acc: 0.1356 - val_loss: 7.8166 - val_acc: 0.0826\n",
      "Epoch 14/50\n",
      "7500/7500 [==============================] - 552s 74ms/step - loss: 5.3821 - acc: 0.1428 - val_loss: 7.8290 - val_acc: 0.0855\n",
      "Epoch 15/50\n",
      "7500/7500 [==============================] - 540s 72ms/step - loss: 5.2564 - acc: 0.1508 - val_loss: 7.8853 - val_acc: 0.0877\n",
      "Epoch 16/50\n",
      "7500/7500 [==============================] - 555s 74ms/step - loss: 5.1213 - acc: 0.1643 - val_loss: 7.8838 - val_acc: 0.0889\n",
      "Epoch 17/50\n",
      "7500/7500 [==============================] - 546s 73ms/step - loss: 5.0001 - acc: 0.1665 - val_loss: 7.9463 - val_acc: 0.0847\n",
      "Epoch 18/50\n",
      "7500/7500 [==============================] - 550s 73ms/step - loss: 4.8765 - acc: 0.1780 - val_loss: 7.8763 - val_acc: 0.0911\n",
      "Epoch 19/50\n",
      "7500/7500 [==============================] - 551s 74ms/step - loss: 4.7652 - acc: 0.1864 - val_loss: 7.8947 - val_acc: 0.0894\n",
      "Epoch 20/50\n",
      "7500/7500 [==============================] - 562s 75ms/step - loss: 4.6458 - acc: 0.2033 - val_loss: 8.0121 - val_acc: 0.0932\n",
      "Epoch 21/50\n",
      "7500/7500 [==============================] - 549s 73ms/step - loss: 4.5388 - acc: 0.2096 - val_loss: 7.9472 - val_acc: 0.0974\n",
      "Epoch 22/50\n",
      "7500/7500 [==============================] - 562s 75ms/step - loss: 4.4287 - acc: 0.2244 - val_loss: 8.0738 - val_acc: 0.0940\n",
      "Epoch 23/50\n",
      "7500/7500 [==============================] - 463s 62ms/step - loss: 4.3160 - acc: 0.2419 - val_loss: 8.0614 - val_acc: 0.0970\n",
      "Epoch 24/50\n",
      "7500/7500 [==============================] - 549s 73ms/step - loss: 4.2076 - acc: 0.2495 - val_loss: 8.1972 - val_acc: 0.0919\n",
      "Epoch 25/50\n",
      "7500/7500 [==============================] - 551s 74ms/step - loss: 4.1089 - acc: 0.2636 - val_loss: 8.0698 - val_acc: 0.1038\n",
      "Epoch 26/50\n",
      "7500/7500 [==============================] - 482s 64ms/step - loss: 3.9927 - acc: 0.2760 - val_loss: 8.2734 - val_acc: 0.1034\n",
      "Epoch 27/50\n",
      "7500/7500 [==============================] - 532s 71ms/step - loss: 3.9039 - acc: 0.2907 - val_loss: 8.1689 - val_acc: 0.1034\n",
      "Epoch 28/50\n",
      "7500/7500 [==============================] - 556s 74ms/step - loss: 3.7949 - acc: 0.3005 - val_loss: 8.2546 - val_acc: 0.1064\n",
      "Epoch 29/50\n",
      "7500/7500 [==============================] - 549s 73ms/step - loss: 3.6938 - acc: 0.3173 - val_loss: 8.3842 - val_acc: 0.1081\n",
      "Epoch 30/50\n",
      "7500/7500 [==============================] - 471s 63ms/step - loss: 3.5951 - acc: 0.3303 - val_loss: 8.3705 - val_acc: 0.1115\n",
      "Epoch 31/50\n",
      "7500/7500 [==============================] - 544s 73ms/step - loss: 3.4864 - acc: 0.3496 - val_loss: 8.3409 - val_acc: 0.1102\n",
      "Epoch 32/50\n",
      "7500/7500 [==============================] - 545s 73ms/step - loss: 3.3893 - acc: 0.3621 - val_loss: 8.4461 - val_acc: 0.1149\n",
      "Epoch 33/50\n",
      "7500/7500 [==============================] - 461s 61ms/step - loss: 3.2932 - acc: 0.3749 - val_loss: 8.3688 - val_acc: 0.1187\n",
      "Epoch 34/50\n",
      "7500/7500 [==============================] - 546s 73ms/step - loss: 3.1904 - acc: 0.3955 - val_loss: 8.4335 - val_acc: 0.1196\n",
      "Epoch 35/50\n",
      "7500/7500 [==============================] - 554s 74ms/step - loss: 3.0940 - acc: 0.4035 - val_loss: 8.5086 - val_acc: 0.1234\n",
      "Epoch 36/50\n",
      "7500/7500 [==============================] - 554s 74ms/step - loss: 2.9962 - acc: 0.4233 - val_loss: 8.6337 - val_acc: 0.1255\n",
      "Epoch 37/50\n",
      "7500/7500 [==============================] - 353s 47ms/step - loss: 2.8999 - acc: 0.4367 - val_loss: 8.5469 - val_acc: 0.1277\n",
      "Epoch 38/50\n",
      "7500/7500 [==============================] - 185s 25ms/step - loss: 2.8168 - acc: 0.4517 - val_loss: 8.6731 - val_acc: 0.1260\n",
      "Epoch 39/50\n",
      "7500/7500 [==============================] - 187s 25ms/step - loss: 2.7285 - acc: 0.4639 - val_loss: 8.7133 - val_acc: 0.1294\n",
      "Epoch 40/50\n",
      "7500/7500 [==============================] - 182s 24ms/step - loss: 2.6328 - acc: 0.4751 - val_loss: 8.9360 - val_acc: 0.1298\n",
      "Epoch 41/50\n",
      "7500/7500 [==============================] - 194s 26ms/step - loss: 2.5508 - acc: 0.4933 - val_loss: 8.8283 - val_acc: 0.1362\n",
      "Epoch 42/50\n",
      "7500/7500 [==============================] - 230s 31ms/step - loss: 2.4462 - acc: 0.5092 - val_loss: 8.7177 - val_acc: 0.1370\n",
      "Epoch 43/50\n",
      "7500/7500 [==============================] - 219s 29ms/step - loss: 2.3664 - acc: 0.5196 - val_loss: 8.8430 - val_acc: 0.1370\n",
      "Epoch 44/50\n",
      "7500/7500 [==============================] - 236s 31ms/step - loss: 2.2738 - acc: 0.5323 - val_loss: 9.0689 - val_acc: 0.1417\n",
      "Epoch 45/50\n",
      "7500/7500 [==============================] - 223s 30ms/step - loss: 2.1913 - acc: 0.5512 - val_loss: 8.8799 - val_acc: 0.1426\n",
      "Epoch 46/50\n",
      "7500/7500 [==============================] - 219s 29ms/step - loss: 2.1129 - acc: 0.5680 - val_loss: 8.9667 - val_acc: 0.1460\n",
      "Epoch 47/50\n",
      "7500/7500 [==============================] - 233s 31ms/step - loss: 2.0209 - acc: 0.5807 - val_loss: 8.9053 - val_acc: 0.1460\n",
      "Epoch 48/50\n",
      "7500/7500 [==============================] - 226s 30ms/step - loss: 1.9434 - acc: 0.5979 - val_loss: 9.0793 - val_acc: 0.1485\n",
      "Epoch 49/50\n",
      "7500/7500 [==============================] - 228s 30ms/step - loss: 1.8705 - acc: 0.6071 - val_loss: 9.1435 - val_acc: 0.1489\n",
      "Epoch 50/50\n",
      "7500/7500 [==============================] - 226s 30ms/step - loss: 1.7982 - acc: 0.6193 - val_loss: 9.0617 - val_acc: 0.1545\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=50,\n",
    "                    batch_size=20,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('name_that_whale_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
