{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               9437312   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4250)              548250    \n",
      "=================================================================\n",
      "Total params: 9,985,562\n",
      "Trainable params: 9,985,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load weights of model trained on AWS\n",
    "model = load_model('./weights/name_that_whale_702.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the test images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15610\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "test_dir = os.path.join(home_dir, 'test/')\n",
    "test_list = os.listdir(test_dir)\n",
    "test_count = len(test_list)\n",
    "print(test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# Model was trained using images of this size\n",
    "image_size = (180,180)\n",
    "\n",
    "def load_image(img_path):\n",
    "    img = image.load_img(img_path, target_size = image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x /= 255\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image', 'Id']\n",
      "9850\n",
      "4250\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "fname = os.path.join(home_dir, 'targets.csv') # targets for both train and validation\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "lines = lines[:-1]\n",
    "\n",
    "ids = [line.split(',')[1] for line in lines]\n",
    "whale_ids = set(ids) # convert to set to remove duplicats\n",
    "whale_ids = list(whale_ids) # convert back to list to make it ordered\n",
    "whale_ids.remove('new_whale')\n",
    "whale_ids = sorted(whale_ids)\n",
    "ids_count = len(whale_ids)\n",
    "\n",
    "print(header)\n",
    "print(len(lines))\n",
    "print(ids_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "Extracting baseline info. Get the top 5 most frequently occuring ids in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "top_5 = Counter(ids).most_common(5)\n",
    "top_5_base = []\n",
    "for i in range(5):\n",
    "    t = top_5[i][0], top_5[i][1]/len(lines)\n",
    "    top_5_base.append(t)\n",
    "\n",
    "top_5_base\n",
    "p_new_whale = top_5_base[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import Xception\n",
    "image_size = (180,180) #adjustable parameter for processed image_size. Run time should \n",
    "\n",
    "conv_base = Xception(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(image_size[0], image_size[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "def predict_labels(augmentation):\n",
    "    # augmentation parameter is true if model was trained in the train_aug.ipynb, otherwise false\n",
    "    labels = np.zeros(shape=(test_count,ids_count))\n",
    "    for i in range(1561):\n",
    "        batch = np.zeros(shape=(batch_size,180,180,3))\n",
    "        for j in range(batch_size):\n",
    "            batch[j] = load_image(os.path.join(test_dir,test_list[i*batch_size + j]))\n",
    "        if augmentation:\n",
    "            labels_batch = model.predict(batch)\n",
    "        else:  \n",
    "            features_batch = conv_base.predict(batch)\n",
    "            features_batch = np.reshape(features_batch,(batch_size,6*6*2048))\n",
    "            labels_batch = model.predict(features_batch)\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    return labels\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_prediction = predict_labels(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('predictions/label_prediction_1.txt','w')\n",
    "f.write(str(label_prediction))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes in a label vector, and returns the top 5 whale ids in order\n",
    "import copy\n",
    "def get_ids(label_vec):\n",
    "    ids = ''\n",
    "    vec = copy.copy(label_vec)\n",
    "    for i in range(5):\n",
    "        max_value = max(vec)\n",
    "        max_index = np.where(vec==max_value)\n",
    "        ids += whale_ids[max_index[0][0]]\n",
    "        vec[max_index] = -1\n",
    "        if i is not 4:\n",
    "            ids += ' '\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes in a label vector, and returns the top 5 whale ids in order, or inserts\n",
    "# new_whale if the proability of a guessed ID is less than p_new\n",
    "p_new = .95\n",
    "def get_ids_or_new_whale(label_vec):\n",
    "    ids = ''\n",
    "    vec = copy.copy(label_vec)\n",
    "    new_whale_guessed = False\n",
    "    for i in range(5):\n",
    "        max_value = max(vec)\n",
    "        if max_value < p_new and new_whale_guessed != True:\n",
    "            ids += 'new_whale'\n",
    "            new_whale_guessed = True\n",
    "        else:\n",
    "            max_index = np.where(vec==max_value)\n",
    "            ids += whale_ids[max_index[0][0]]\n",
    "            vec[max_index] = -1\n",
    "        if i is not 4:\n",
    "            ids += ' '\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_5_prediction(label_vec):\n",
    "    top_5_pred = []\n",
    "    vec = copy.copy(label_vec)\n",
    "    for i in range(5):\n",
    "        max_value = max(vec)\n",
    "        max_index = np.where(vec==max_value)\n",
    "        max_id = whale_ids[max_index[0][0]]\n",
    "        p = max_id, max_value\n",
    "        top_5_pred.append(p)\n",
    "        vec[max_index] = -1\n",
    "    return top_5_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_whale w_b0362e2 w_5a2075e w_cae7677 w_c00534d'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ids_or_new_whale(label_prediction[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790890276432\n",
      "  w_eb0a6ed new_whale w_886257d w_b0e05b1 w_b0362e2\n",
      "0.188661500812\n",
      "  new_whale w_6556c5c w_a254eb0 w_392bee3 w_540fd73\n",
      "0.0436196923256\n",
      "  new_whale w_98baff9 w_74adf0b w_97f5054 w_ddbf533\n",
      "0.999880671501\n",
      "  w_7c7a78c new_whale w_9ca943b w_26edeb8 w_2fe43c7\n",
      "0.130795732141\n",
      "  new_whale w_1da7080 w_8459e39 w_41fa033 w_680e011\n",
      "0.35473921895\n",
      "  new_whale w_89e159a w_95874a5 w_dfbfe10 w_bb2d34d\n",
      "0.333799034357\n",
      "  new_whale w_b0e05b1 w_cd70e8b w_1287fbc w_0e737d0\n",
      "0.730777025223\n",
      "  w_ed117b3 new_whale w_a254eb0 w_d141590 w_3027b8f\n",
      "0.374759882689\n",
      "  new_whale w_f4e03d4 w_6c803bf w_a524549 w_9c5ed68\n",
      "0.253903359175\n",
      "  new_whale w_89e159a w_abe383e w_32a920b w_1ecfe96\n",
      "0.17209880054\n",
      "  new_whale w_95874a5 w_12c3d3d w_1287fbc w_25871da\n",
      "0.225434482098\n",
      "  new_whale w_78f2e92 w_3e1ba5b w_987a36f w_71c7322\n",
      "0.178572177887\n",
      "  new_whale w_b0e05b1 w_c10ffe9 w_0e737d0 w_4e68ddc\n",
      "0.999999761581\n",
      "  w_43b50e5 new_whale w_95874a5 w_97f5054 w_3f365f3\n",
      "0.0816478431225\n",
      "  new_whale w_cae7677 w_fe49bc4 w_1287fbc w_b0aed4a\n",
      "0.196595430374\n",
      "  new_whale w_351a1e1 w_dfbfe10 w_89e159a w_daeb296\n",
      "0.786136865616\n",
      "  w_90ec71a new_whale w_218b25e w_c0d494d w_9ceb05d\n",
      "0.268524706364\n",
      "  new_whale w_ff1b64c w_b0362e2 w_b0e05b1 w_eb0a6ed\n",
      "0.254081189632\n",
      "  new_whale w_4c9d3df w_7b035cc w_064ab78 w_d88328d\n",
      "0.770085811615\n",
      "  w_2fd21ec new_whale w_fba3bde w_0988bbb w_ca5f17f\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(max(label_prediction[i]))\n",
    "    print('  ' + get_ids_or_new_whale(label_prediction[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = 'Image,Id\\n'\n",
    "for i in range(15610):\n",
    "    prediction += test_list[i]\n",
    "    prediction += ', '\n",
    "    prediction += get_ids_or_new_whale(label_prediction[i])\n",
    "    prediction += '\\n'\n",
    "\n",
    "#print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('predictions/prediction_p_new=.95.csv','w')\n",
    "f.write(prediction)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
