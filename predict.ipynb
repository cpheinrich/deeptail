{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               9437312   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4250)              548250    \n",
      "=================================================================\n",
      "Total params: 9,985,562\n",
      "Trainable params: 9,985,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Load weights of model trained on AWS\n",
    "model = load_model('./weights/name_that_whale_702.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the test images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15610\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "test_dir = os.path.join(home_dir, 'test/')\n",
    "test_list = os.listdir(test_dir)\n",
    "test_count = len(test_list)\n",
    "print(test_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# Model was trained using images of this size\n",
    "image_size = (180,180)\n",
    "\n",
    "def load_image(img_path):\n",
    "    img = image.load_img(img_path, target_size = image_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x /= 255\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Image', 'Id']\n",
      "9850\n",
      "4250\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "home_dir = os.getcwd()\n",
    "fname = os.path.join(home_dir, 'targets.csv') # targets for both train and validation\n",
    "\n",
    "f = open(fname)\n",
    "data = f.read()\n",
    "f.close()\n",
    "\n",
    "lines = data.split('\\n')\n",
    "header = lines[0].split(',')\n",
    "lines = lines[1:]\n",
    "lines = lines[:-1]\n",
    "\n",
    "ids = [line.split(',')[1] for line in lines]\n",
    "whale_ids = set(ids) # convert to set to remove duplicats\n",
    "whale_ids = list(whale_ids) # convert back to list to make it ordered\n",
    "whale_ids.remove('new_whale')\n",
    "whale_ids = sorted(whale_ids)\n",
    "ids_count = len(whale_ids)\n",
    "\n",
    "print(header)\n",
    "print(len(lines))\n",
    "print(ids_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting baseline info. Get the top 5 most frequently occuring ids in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "top_5 = Counter(ids).most_common(5)\n",
    "top_5_base = []\n",
    "for i in range(5):\n",
    "    t = top_5[i][0], top_5[i][1]/len(lines)\n",
    "    top_5_base.append(t)\n",
    "\n",
    "top_5_base\n",
    "p_new_whale = top_5_base[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import Xception\n",
    "image_size = (180,180) #adjustable parameter for processed image_size. Run time should \n",
    "\n",
    "conv_base = Xception(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(image_size[0], image_size[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "def predict_labels(augmentation):\n",
    "    # augmentation parameter is true if model was trained in the train_aug.ipynb, otherwise false\n",
    "    labels = np.zeros(shape=(test_count,ids_count))\n",
    "    for i in range(1561):\n",
    "        batch = np.zeros(shape=(batch_size,180,180,3))\n",
    "        for j in range(batch_size):\n",
    "            batch[j] = load_image(os.path.join(test_dir,test_list[i*batch_size + j]))\n",
    "        if augmentation:\n",
    "            labels_batch = model.predict(batch)\n",
    "        else:  \n",
    "            features_batch = conv_base.predict(batch)\n",
    "            features_batch = np.reshape(features_batch,(batch_size,6*6*2048))\n",
    "            labels_batch = model.predict(features_batch)\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    return labels\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label_prediction = predict_labels(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('predictions/label_prediction_0.txt','w')\n",
    "f.write(str(label_prediction))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes in a label vector, and returns the top 5 whale ids in order\n",
    "def get_ids(label_vec):\n",
    "    ids = ''\n",
    "    vec = label_vec\n",
    "    for i in range(5):\n",
    "        max_value = max(vec)\n",
    "        max_index = np.where(vec==max_value)\n",
    "        ids += whale_ids[max_index[0][0]]\n",
    "        vec[max_index] = -1\n",
    "        if i is not 4:\n",
    "            ids += ' '\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function takes in a label vector, and returns the top 5 whale ids in order, and guesses \n",
    "p_new = p_new_whale\n",
    "def get_ids_or_new_whale(label_vec):\n",
    "    ids = ''\n",
    "    vec = label_vec\n",
    "    new_whale_guessed = False\n",
    "    for i in range(5):\n",
    "        max_value = max(vec)\n",
    "        if max_value < p_new and new_whale_guessed != True:\n",
    "            ids += 'new_whale'\n",
    "            new_whale_guessed = True\n",
    "        else:\n",
    "            max_index = np.where(vec==max_value)\n",
    "            ids += whale_ids[max_index[0][0]]\n",
    "            vec[max_index] = -1\n",
    "        if i is not 4:\n",
    "            ids += ' '\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_5_prediction(label_vec):\n",
    "    top_5_pred = []\n",
    "    vec = label_vec\n",
    "    for i in range(5):\n",
    "        max_value = max(vec)\n",
    "        max_index = np.where(vec==max_value)\n",
    "        max_id = whale_ids[max_index[0][0]]\n",
    "        p = max_id, max_value\n",
    "        top_5_pred.append(p)\n",
    "        vec[max_index] = -1\n",
    "    return top_5_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w_98baff9', 0.043619692325592041),\n",
       " ('w_74adf0b', 0.03126254677772522),\n",
       " ('w_97f5054', 0.030560841783881187),\n",
       " ('w_ddbf533', 0.019387600943446159),\n",
       " ('w_cef690d', 0.012810902670025826)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5_prediction(label_prediction[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790890276432\n",
      "0.188661500812\n",
      "0.0436196923256\n",
      "0.999880671501\n",
      "0.130795732141\n",
      "0.35473921895\n",
      "0.333799034357\n",
      "0.730777025223\n",
      "0.374759882689\n",
      "0.253903359175\n",
      "0.17209880054\n",
      "0.225434482098\n",
      "0.178572177887\n",
      "0.999999761581\n",
      "0.0816478431225\n",
      "0.196595430374\n",
      "0.786136865616\n",
      "0.268524706364\n",
      "0.254081189632\n",
      "0.770085811615\n",
      "0.0685156732798\n",
      "0.0289645101875\n",
      "0.127820253372\n",
      "0.040358517319\n",
      "0.647751927376\n",
      "0.0687883496284\n",
      "0.98959094286\n",
      "0.890912234783\n",
      "0.513904511929\n",
      "0.0572819747031\n",
      "0.497076123953\n",
      "0.246196120977\n",
      "0.191147491336\n",
      "0.0632137134671\n",
      "0.0425635203719\n",
      "0.205020770431\n",
      "0.0805441886187\n",
      "0.376503765583\n",
      "0.252388656139\n",
      "0.934563457966\n",
      "0.140293240547\n",
      "0.164337962866\n",
      "0.143307521939\n",
      "0.341555595398\n",
      "0.177260652184\n",
      "0.0405299626291\n",
      "0.0528962612152\n",
      "0.212522774935\n",
      "0.414223372936\n",
      "0.0446017980576\n",
      "0.432242006063\n",
      "0.161375388503\n",
      "0.0686145871878\n",
      "0.26704621315\n",
      "0.149836808443\n",
      "0.102045580745\n",
      "0.477504223585\n",
      "0.137165606022\n",
      "0.15158714354\n",
      "0.159041211009\n",
      "0.0450534895062\n",
      "0.820578098297\n",
      "0.269502192736\n",
      "0.562408447266\n",
      "0.0903078615665\n",
      "0.997298896313\n",
      "0.17979452014\n",
      "0.0418405868113\n",
      "0.0429618880153\n",
      "0.226796224713\n",
      "0.182323560119\n",
      "0.981791377068\n",
      "0.244352161884\n",
      "0.0857570618391\n",
      "0.178306907415\n",
      "0.444871306419\n",
      "0.140554338694\n",
      "0.232860818505\n",
      "0.208282738924\n",
      "0.380589067936\n",
      "0.165792196989\n",
      "0.604001045227\n",
      "0.00780662149191\n",
      "0.119239449501\n",
      "0.206358119845\n",
      "0.511962175369\n",
      "0.143546059728\n",
      "0.209210172296\n",
      "0.332959592342\n",
      "0.215826570988\n",
      "0.175661891699\n",
      "0.157544493675\n",
      "0.199807822704\n",
      "0.203139185905\n",
      "0.396975547075\n",
      "0.613057076931\n",
      "0.300666213036\n",
      "0.650724470615\n",
      "0.13747189939\n",
      "0.0371945388615\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    print(max(label_prediction[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = 'Image,Id\\n'\n",
    "for i in range(15610):\n",
    "    prediction += test_list[i]\n",
    "    prediction += ', '\n",
    "    prediction += get_ids(label_prediction[i])\n",
    "    prediction += '\\n'\n",
    "\n",
    "#print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('predictions/prediction_2.csv','w')\n",
    "f.write(prediction)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "baseline = 'new_whale w_1287fbc w_98baff9 w_7554f44 w_1eafe46'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
